<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KEtta</title>
    <style>
        body {
            margin: 0;
            background-color: transparent;
            color: #fff;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen,
                Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            overflow: hidden;
        }
        #siri-container {
            width: 80vw;
            height: 50vh;
            max-width: 600px;
            max-height: 400px;
        }
        .controls {
            margin-top: 20px;
            display: flex;
            gap: 10px;
        }
        button {
            background-color: #333;
            border: 1px solid #555;
            color: #fff;
            padding: 10px 20px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 14px;
            transition: background-color 0.2s;
        }
        button:hover {
            background-color: #444;
        }
        button.active {
            background-color: #007aff;
            border-color: #007aff;
        }
        p {
            max-width: 600px;
            text-align: center;
            color: #888;
        }
    </style>
</head>
<body>

    <h1>Siri-like Audio Orb (Remote Control)</h1>
    <p>The orb's state is now controlled by an external Python script. The listening animation is driven by a live audio stream from the VAD script.</p>
    
    <div id="siri-container"></div>

    <div class="controls">
        <button id="thinkBtn">Simulate Thinking</button>
        <button id="speakBtn">Simulate Speaking</button>
        <button id="resetBtn">Reset to Idle</button>
    </div>

    <!-- Import Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- Simplex Noise for organic motion -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/simplex-noise/2.4.0/simplex-noise.min.js"></script>

    <script>
        // --- Basic Setup ---
        const container = document.getElementById('siri-container');
        let scene, camera, renderer, sphere, uniforms, clock;
        const simplex = new SimplexNoise();

        // --- State Management ---
        let currentModeName = 'idle';
        let targetMode = 0.0; 
        let currentMode = 0.0; 
        const TRANSITION_SPEED = 0.04;
        let currentLoudness = 0.0; // NEW: This will be updated by the WebSocket

        // --- Shader Code (The magic happens here) ---
        // UNCHANGED from original, so it is omitted here for brevity.
        const vertexShader = `
            uniform float u_time;
            uniform float u_loudness;
            uniform float u_mode;
            vec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
            vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
            vec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); }
            vec4 taylorInvSqrt(vec4 r) { return 1.79284291400159 - 0.85373472095314 * r; }
            float snoise(vec3 v) {
                const vec2 C = vec2(1.0/6.0, 1.0/3.0); const vec4 D = vec4(0.0, 0.5, 1.0, 2.0);
                vec3 i = floor(v + dot(v, C.yyy)); vec3 x0 = v - i + dot(i, C.xxx);
                vec3 g = step(x0.yzx, x0.xyz); vec3 l = 1.0 - g; vec3 i1 = min(g.xyz, l.zxy);
                vec3 i2 = max(g.xyz, l.zxy); vec3 x1 = x0 - i1 + C.xxx; vec3 x2 = x0 - i2 + C.yyy;
                vec3 x3 = x0 - D.yyy; i = mod289(i);
                vec4 p = permute(permute(permute(i.z + vec4(0.0, i1.z, i2.z, 1.0)) + i.y + vec4(0.0, i1.y, i2.y, 1.0)) + i.x + vec4(0.0, i1.x, i2.x, 1.0));
                float n_ = 0.142857142857; vec3 ns = n_ * D.wyz - D.xzx;
                vec4 j = p - 49.0 * floor(p * ns.z * ns.z); vec4 x_ = floor(j * ns.z);
                vec4 y_ = floor(j - 7.0 * x_); vec4 x = x_ * ns.x + ns.yyyy;
                vec4 y = y_ * ns.x + ns.yyyy; vec4 h = 1.0 - abs(x) - abs(y);
                vec4 b0 = vec4(x.xy, y.xy); vec4 b1 = vec4(x.zw, y.zw);
                vec4 s0 = floor(b0)*2.0 + 1.0; vec4 s1 = floor(b1)*2.0 + 1.0;
                vec4 sh = -step(h, vec4(0.0)); vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy;
                vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww;
                vec3 p0 = vec3(a0.xy,h.x); vec3 p1 = vec3(a0.zw,h.y);
                vec3 p2 = vec3(a1.xy,h.z); vec3 p3 = vec3(a1.zw,h.w);
                vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2,p2), dot(p3,p3)));
                p0 *= norm.x; p1 *= norm.y; p2 *= norm.z; p3 *= norm.w;
                vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);
                m = m * m; return 42.0 * dot(m*m, vec4(dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3)));
            }
            varying vec3 v_normal;
            void main() {
                v_normal = normal;
                float idle_displacement = 0.0;
                float listen_noise = snoise(position * 4.0 + u_time * 0.4);
                float listen_displacement = listen_noise * u_loudness * 0.6;
                float think_displacement = snoise(position * 3.0 + u_time * 0.5) * 0.15;
                float speak_pulse = (sin(u_time * 5.0) + 1.0) / 2.0;
                float speak_wobble = snoise(position * 4.0 + u_time * 2.0) * speak_pulse * 0.2;
                float speak_displacement = speak_wobble;
                float displacement = 0.0;
                displacement = mix(idle_displacement, listen_displacement, smoothstep(0.0, 1.0, u_mode));
                displacement = mix(displacement, think_displacement, smoothstep(1.0, 2.0, u_mode));
                displacement = mix(displacement, speak_displacement, smoothstep(2.0, 3.0, u_mode));
                vec3 pos = position + normal * displacement;
                gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
            }
        `;

        const fragmentShader = `
            uniform float u_time;
            uniform vec3 u_color1;
            uniform vec3 u_color2;
            uniform vec3 u_color3;
            varying vec3 v_normal;
            void main() {
                float intensity = pow(0.6 - dot(v_normal, vec3(0.0, 0.0, 1.0)), 2.0);
                vec3 color_mix1 = mix(u_color1, u_color2, smoothstep(0.0, 0.5, intensity));
                vec3 final_color = mix(color_mix1, u_color3, smoothstep(0.4, 1.0, intensity));
                gl_FragColor = vec4(final_color, intensity * 1.5);
            }
        `;

        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, container.clientWidth / container.clientHeight, 0.1, 1000);
            camera.position.z = 2.5;
            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(container.clientWidth, container.clientHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            container.appendChild(renderer.domElement);
            
            const geometry = new THREE.IcosahedronGeometry(1, 64);
            uniforms = {
                u_time: { value: 0.0 },
                u_loudness: { value: 0.0 },
                u_mode: { value: 0.0 },
                u_color1: { value: new THREE.Color('#3c00ff') },
                u_color2: { value: new THREE.Color('#00b3ff') },
                u_color3: { value: new THREE.Color('#00ffdd') },
            };
            const material = new THREE.ShaderMaterial({
                vertexShader,
                fragmentShader,
                uniforms,
                transparent: true,
                blending: THREE.AdditiveBlending,
                depthTest: false,
            });
            sphere = new THREE.Mesh(geometry, material);
            scene.add(sphere);
            clock = new THREE.Clock();
            window.addEventListener('resize', onWindowResize, false);
            animate();
        }

        function onWindowResize() {
            camera.aspect = container.clientWidth / container.clientHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(container.clientWidth, container.clientHeight);
        }

        function animate() {
            requestAnimationFrame(animate);
            const elapsedTime = clock.getElapsedTime();
            
            currentMode += (targetMode - currentMode) * TRANSITION_SPEED;
            uniforms.u_mode.value = currentMode;
            uniforms.u_time.value = elapsedTime;

            // Smoothly update loudness based on the value from the WebSocket
            let targetLoudness = 0.0;
            // Only apply loudness if we are in or near the 'listening' mode
            if (currentMode > 0.5 && currentMode < 1.5) {
                targetLoudness = currentLoudness;
            }
            uniforms.u_loudness.value += (targetLoudness - uniforms.u_loudness.value) * 0.2;
            
            sphere.rotation.y = elapsedTime * 0.1;
            sphere.rotation.x = elapsedTime * 0.05;
            renderer.render(scene, camera);
        }
        
        // --- Control Logic ---
        const thinkBtn = document.getElementById('thinkBtn');
        const speakBtn = document.getElementById('speakBtn');
        const resetBtn = document.getElementById('resetBtn');
        const allButtons = [thinkBtn, speakBtn, resetBtn];

        function setActiveButton(activeBtnId) {
            allButtons.forEach(btn => btn.classList.remove('active'));
            const activeBtn = document.getElementById(activeBtnId);
            if (activeBtn) {
                activeBtn.classList.add('active');
            }
        }

        function setMode(modeName) {
            currentModeName = modeName;
            switch(modeName) {
                case 'listening':
                    targetMode = 1.0;
                    // No button for listening anymore, state is set externally
                    break;
                case 'thinking':
                    targetMode = 2.0;
                    setActiveButton('thinkBtn');
                    break;
                case 'speaking':
                    targetMode = 3.0;
                    setActiveButton('speakBtn');
                    break;
                case 'reset':
                default:
                    targetMode = 0.0;
                    setActiveButton('resetBtn');
                    break;
            }
        }

        thinkBtn.addEventListener('click', () => setMode('thinking'));
        speakBtn.addEventListener('click', () => setMode('speaking'));
        resetBtn.addEventListener('click', () => setMode('reset'));
        
        // --- WebSocket Connection for Loudness ---
        function connectWebSocket() {
            const ws = new WebSocket('ws://localhost:8765');

            ws.onmessage = (event) => {
                // The WebSocket sends loudness values as strings
                const loudness = parseFloat(event.data);
                if (!isNaN(loudness)) {
                    currentLoudness = loudness;
                }
            };

            ws.onopen = () => {
                console.log('WebSocket connection established for loudness stream.');
            };

            ws.onclose = () => {
                console.log('WebSocket connection closed. Attempting to reconnect in 3 seconds...');
                // Reset loudness to 0 when connection is lost
                currentLoudness = 0;
                setTimeout(connectWebSocket, 3000);
            };

            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                ws.close();
            };
        }

        // Start the application
        init();
        connectWebSocket();
        setMode('reset');

    </script>
</body>
</html>
